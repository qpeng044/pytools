{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clang.cindex\n",
    "import os\n",
    "\n",
    "def get_caller_function_name(call_expr_cursor):\n",
    "    # Iterate through parent cursors until a function declaration is found\n",
    "    parent = call_expr_cursor.semantic_parent\n",
    "    while parent and parent.kind != clang.cindex.CursorKind.FUNCTION_DECL:\n",
    "        parent = parent.semantic_parent\n",
    "\n",
    "    if parent and parent.kind == clang.cindex.CursorKind.FUNCTION_DECL:\n",
    "        return parent.spelling  # Return the function name\n",
    "    else:\n",
    "        return None  # No caller function found (e.g., top-level call)\n",
    "\n",
    "\n",
    "\n",
    "def analyze_function_relationships(root_dir):\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(\n",
    "        root_dir,\n",
    "        args=['-std=c++11']  # Specify language and include path\n",
    "    )\n",
    "\n",
    "    function_calls = {}\n",
    "    for cursor in translation_unit.cursor.walk_preorder():\n",
    "        if cursor.kind == clang.cindex.CursorKind.FUNCTION_DECL:\n",
    "            function_name = cursor.spelling\n",
    "            function_calls[function_name] = []\n",
    "            for child in cursor.get_children():\n",
    "                if child.kind == clang.cindex.CursorKind.CALL_EXPR:\n",
    "                    caller_name = get_caller_function_name(child)\n",
    "                    function_calls[function_name].append(caller_name)\n",
    "\n",
    "    # Further analysis and visualization using function_calls data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    analyze_function_relationships(\"/home/tfpeng/codeparser/test/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from clang import cindex\n",
    "\n",
    "\n",
    "folder_path = \"/home/tfpeng/codeparser/\"\n",
    "index = cindex.Index.create()\n",
    "\n",
    "# 积累所有C++代码\n",
    "all_cpp_code = \"\"\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith((\".cpp\",\".hpp\")) :\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r',errors='ignore') as f:\n",
    "                all_cpp_code += f.read()\n",
    "\n",
    "# 创建TranslationUnit\n",
    "tu = index.parse('in-memory.cpp', args=['-std=c++11',f'-O0'], unsaved_files=[('in-memory.cpp', all_cpp_code)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_function_callers(cursor, target_function_name):\n",
    "    callers = []\n",
    "\n",
    "    for child in cursor.get_children():\n",
    "        if child.kind == cindex.CursorKind.CALL_EXPR:\n",
    "            called_function = child.get_definition()\n",
    "            if called_function and called_function.spelling == target_function_name:\n",
    "                caller = cursor.get_definition()\n",
    "                if caller:\n",
    "                    callers.append(caller.spelling)\n",
    "        else:\n",
    "            # 递归调用，继续查找子节点\n",
    "            callers.extend(find_function_callers(child, target_function_name))\n",
    "            \n",
    "\n",
    "    return callers\n",
    "def find_function_callers2(cursor, target_function_name):\n",
    "    callers = []\n",
    "    for child in cursor.get_children():\n",
    "        if child.kind == cindex.CursorKind.CALL_EXPR:\n",
    "            # 获取被调用的函数（可能是函数声明而非定义）\n",
    "            called_function = child.referenced\n",
    "            if called_function and called_function.spelling == target_function_name:\n",
    "                # 获取调用该函数的函数\n",
    "                caller = cursor.get_definition()\n",
    "                if caller:\n",
    "                    callers.append(caller.spelling)\n",
    "        else:\n",
    "            # 递归调用，继续查找子节点\n",
    "            callers.extend(find_function_callers2(child, target_function_name))\n",
    "\n",
    "    return callers\n",
    "\n",
    "def find_function_cursor(root_cursor, function_name):\n",
    "    for child in root_cursor.get_children():\n",
    "        if child.kind == clang.cindex.CursorKind.FUNCTION_DECL and child.spelling == function_name:\n",
    "            return child\n",
    "        result = find_function_cursor(child, function_name)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "def get_all_functions(cursor):\n",
    "    functions = []\n",
    "\n",
    "    for child in cursor.get_children():\n",
    "        if child.kind == cindex.CursorKind.FUNCTION_DECL:\n",
    "            functions.append(child.spelling)\n",
    "        else:\n",
    "            # 递归调用，继续查找子节点\n",
    "            functions.extend(get_all_functions(child))\n",
    "\n",
    "    return functions\n",
    "# caller=find_function_callers(tu.cursor,\"SetMotorSpeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_function=get_all_functions(tu.cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Create433ServerManager\" in all_function:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caller_function_name(call_expr_cursor):\n",
    "    parent = call_expr_cursor.semantic_parent\n",
    "    while parent and parent.kind != cindex.CursorKind.FUNCTION_DECL:\n",
    "        parent = parent.semantic_parent\n",
    "\n",
    "    if parent and parent.kind == cindex.CursorKind.FUNCTION_DECL:\n",
    "        return parent.spelling\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_callers_for_function(function_name):\n",
    "    function_cursor = find_function_cursor(tu.cursor, function_name)\n",
    "    if function_cursor:\n",
    "        callers = []\n",
    "        for child in function_cursor.get_children():\n",
    "            if child.kind == cindex.CursorKind.CALL_EXPR:\n",
    "                caller_name = get_caller_function_name(child)\n",
    "                if caller_name:\n",
    "                    callers.append(caller_name)\n",
    "        return callers\n",
    "    else:\n",
    "        return None  # Function not found\n",
    "\n",
    "def find_function_cursor(root_cursor, function_name):\n",
    "    for child in root_cursor.get_children():\n",
    "        if(hasattr(child,\"spelling\")):\n",
    "            print(child.spelling)\n",
    "        if child.kind == cindex.CursorKind.FUNCTION_DECL and child.spelling == function_name:\n",
    "            return child\n",
    "        result = find_function_cursor(child, function_name)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "caller=get_callers_for_function(\"Create433ServerManager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def cursor_to_dict(cursor):\n",
    "    return {\n",
    "        'kind': cursor.kind.name,\n",
    "        'spelling': cursor.spelling,\n",
    "        'children': [cursor_to_dict(child) for child in cursor.get_children()]\n",
    "    }\n",
    "\n",
    "def save_ast_to_json(file_path, translation_unit):\n",
    "    root_cursor = translation_unit.cursor\n",
    "    ast_dict = cursor_to_dict(root_cursor)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(ast_dict, f, indent=2)\n",
    "\n",
    "save_ast_to_json(\"ast.json\", tu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from clang.cindex import CursorKind\n",
    "nodes = []\n",
    "\n",
    "def traverse(node):\n",
    "    node_dict = {}\n",
    "    node_dict['kind'] = node.kind \n",
    "    node_dict['location'] = (node.location.file, node.location.line, node.location.column)\n",
    "    \n",
    "    if node.kind == cindex.CursorKind.NAMESPACE:\n",
    "        node_dict['name'] = node.displayname\n",
    "    \n",
    "    children = [traverse(c) for c in node.get_children()]\n",
    "    if len(children) > 0:\n",
    "        node_dict['children'] = children\n",
    "        \n",
    "    nodes.append(node_dict)\n",
    "    \n",
    "    return node_dict\n",
    "\n",
    "\n",
    "\n",
    "class CursorKindEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, CursorKind):\n",
    "            return obj.value\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "root = tu.cursor\n",
    "traverse(root)\n",
    "\n",
    "with open('ast1.json', 'w') as f:\n",
    "    json.dump(nodes, f, indent=4,cls=CursorKindEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from clang import cindex\n",
    "\n",
    "def analyze_cpp_files(folder_path):\n",
    "    # 初始化libclang\n",
    "    index = cindex.Index.create()\n",
    "\n",
    "    # 存储所有AST的列表\n",
    "    all_asts = []\n",
    "\n",
    "    # 遍历文件夹中的所有cpp文件\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".cpp\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                ast_dict = analyze_cpp_file(file_path, index)\n",
    "                all_asts.append(ast_dict)\n",
    "\n",
    "        # 递归调用自己，处理子文件夹\n",
    "        for dir_name in dirs:\n",
    "            subfolder_path = os.path.join(root, dir_name)\n",
    "            analyze_cpp_files(subfolder_path)\n",
    "\n",
    "    # 将所有AST转换为JSON并写入文件\n",
    "    with open(\"all_asts.json\", \"w\") as json_file:\n",
    "        json.dump(all_asts, json_file, indent=2)\n",
    "\n",
    "def analyze_cpp_file(file_path, index):\n",
    "    # 打开C++文件\n",
    "    with open(file_path, 'r',errors='ignore') as f:\n",
    "        cpp_code = f.read()\n",
    "\n",
    "    # 创建TranslationUnit\n",
    "    if file_path.endswith(\".cpp\"):\n",
    "        tu = index.parse(file_path, args=['-std=c++11'], unsaved_files=[(file_path, cpp_code)])\n",
    "    else:\n",
    "        tu = index.parse(file_path, unsaved_files=[(file_path, cpp_code)])\n",
    "\n",
    "    # 分析TranslationUnit并生成AST字典\n",
    "    ast_dict = []\n",
    "    for cursor in tu.cursor.walk_preorder():\n",
    "        ast_dict.append({\n",
    "            'kind': cursor.kind.name,\n",
    "            'spelling': cursor.spelling,\n",
    "            'location': [cursor.location.line, cursor.location.column],\n",
    "            'children': [child.spelling for child in cursor.get_children()]\n",
    "        })\n",
    "\n",
    "    return ast_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"/home/tfpeng/codeparser/test/\"\n",
    "    analyze_cpp_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from clang import cindex\n",
    "\n",
    "def merge_files(directory_path):\n",
    "    merged_file_path = \"merged_file.cpp\"\n",
    "\n",
    "    with open(merged_file_path, \"w\") as merged_file:\n",
    "            # 遍历文件夹中的所有cpp文件\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith((\".c\",\".cpp\")):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    with open(file_path, 'r',errors='ignore') as f:\n",
    "                        cpp_code = f.read()\n",
    "                        merged_file.write(cpp_code)\n",
    "\n",
    "    return merged_file_path\n",
    "\n",
    "def analyze_merged_file(file_path, index):\n",
    "    # 打开合并的C++和C文件\n",
    "    with open(file_path, 'r') as f:\n",
    "        merged_code = f.read()\n",
    "\n",
    "    # 创建TranslationUnit\n",
    "    tu = index.parse(file_path, args=['-std=c++11'], unsaved_files=[(file_path, merged_code)])\n",
    "\n",
    "    # 分析TranslationUnit并生成AST字典\n",
    "    ast_dict = []\n",
    "    for cursor in tu.cursor.walk_preorder():\n",
    "        ast_dict.append({\n",
    "            'kind': cursor.kind.name,\n",
    "            'spelling': cursor.spelling,\n",
    "            'children': [child.spelling for child in cursor.get_children()]\n",
    "        })\n",
    "\n",
    "    return ast_dict\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    merged_file_path = merge_files(directory_path)\n",
    "\n",
    "    # 初始化libclang\n",
    "    index = cindex.Index.create()\n",
    "\n",
    "    print(f\"Generating AST for merged file: {merged_file_path}\")\n",
    "    ast_result = analyze_merged_file(merged_file_path, index)\n",
    "\n",
    "    # 将AST结果转换为JSON并写入文件\n",
    "    with open(\"merged_ast.json\", \"w\") as json_file:\n",
    "        json.dump(ast_result, json_file, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"/home/tfpeng/codeparser/\"\n",
    "    process_directory(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 可用，但cpp文件下的成员函数无法解析，原因是找不到头文件，找不到类的定义\n",
    "import os\n",
    "import clang.cindex\n",
    "from clang.cindex import Index, CursorKind\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "file_exclude_list=[r'^(?!arm_).*']# [非arm_开头]\n",
    "func_exclude_list=[r'^(?!__).*'] #[非__开头]\n",
    "\n",
    "cpp_and_c_keywords_and_operators = [\n",
    "    'alignas', 'alignof', 'and', 'and_eq', 'asm', 'auto', 'bitand', 'bitor', 'bool', 'break', 'case', 'catch', 'char',\n",
    "    'char8_t', 'char16_t', 'char32_t', 'class', 'compl', 'concept', 'const', 'consteval', 'constexpr', 'const_cast',\n",
    "    'continue', 'co_await', 'co_return', 'co_yield', 'decltype', 'default', 'delete', 'do', 'double', 'dynamic_cast',\n",
    "    'else', 'enum', 'explicit', 'export', 'extern', 'false', 'float', 'for', 'friend', 'goto', 'if', 'inline', 'int',\n",
    "    'long', 'mutable', 'namespace', 'new', 'noexcept', 'not', 'not_eq', 'nullptr', 'operator', 'or', 'or_eq', 'private',\n",
    "    'protected', 'public', 'register', 'reinterpret_cast', 'requires', 'return', 'short', 'signed', 'sizeof', 'static',\n",
    "    'static_assert', 'static_cast', 'struct', 'switch', 'template', 'this', 'thread_local', 'throw', 'true', 'try',\n",
    "    'typedef', 'typeid', 'typename', 'union', 'unsigned', 'using', 'virtual', 'void', 'volatile', 'wchar_t', 'while',\n",
    "    'xor', 'xor_eq','NULL','null','int8_t','uint8_t','int16_t','uint16_t','int32_t','uint32_t','ifdef','ifndef','endif'\n",
    "    'auto', 'break', 'case', 'char', 'const', 'continue', 'default', 'do', 'double', 'else', 'enum', 'extern', 'float',\n",
    "    'for', 'goto', 'if', 'inline', 'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static', 'struct',\n",
    "    'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while',\n",
    "    '+', '-', '*', '/', '%', '+=', '-=', '*=', '/=', '%=', '++', '--', '<<', '>>', '<<=', '>>=', '&', '|', '^',\n",
    "    '&=', '|=', '^=', '~', '!', '&&', '||', '==', '!=', '<', '>', '<=', '>=', '?', ':', '=', '+=', '-=', '*=', '/=',\n",
    "]\n",
    "\n",
    "def find_header_files(root_folder):\n",
    "    header_files = []\n",
    "    \n",
    "    # 遍历文件夹及其子文件夹\n",
    "    for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "        # 使用glob模块查找.h和.hpp文件\n",
    "        header_files.extend(glob.glob(os.path.join(foldername, '*.h')))\n",
    "        header_files.extend(glob.glob(os.path.join(foldername, '*.hpp')))\n",
    "\n",
    "    return header_files\n",
    "folder_path = \"/home/tfpeng/codeparser/\"  # 替换为实际的文件夹路径\n",
    "header_files=find_header_files(folder_path)\n",
    "\n",
    "def get_included_headers(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # 使用正则表达式匹配 #include 语句\n",
    "    include_pattern = re.compile(r'#include\\s*[\"<](.*?)[\">]')\n",
    "    included_headers = include_pattern.findall(content)\n",
    "\n",
    "    return included_headers\n",
    "\n",
    "def run_clang(root,file):\n",
    "    # 使用libclang分析文件，获取函数信息\n",
    "    file_path = os.path.join(root, file)\n",
    "    index = Index.create()\n",
    "    if file_path.endswith((\".c\")):\n",
    "        translation_unit = index.parse(file_path)\n",
    "    else:\n",
    "        with open(file_path, 'r',errors='ignore') as f:\n",
    "            cpp_code = f.read()\n",
    "        \n",
    "        args =  '-x c++ --std=c++11'.split()\n",
    "        include_header=get_included_headers(file_path)\n",
    "        for header in include_header:\n",
    "            for header_path in header_files:\n",
    "                if(header_path.endswith(header)):\n",
    "                    args.append(f'-I{os.path.dirname(header_path)}')\n",
    "        translation_unit = index.parse(file_path, args=args,unsaved_files=[(file_path, cpp_code)])\n",
    "    return translation_unit\n",
    "\n",
    "def locate_function_body(cursor):\n",
    "    # 定位函数体\n",
    "    start_line = cursor.extent.start.line\n",
    "    end_line = cursor.extent.end.line\n",
    "    func_body=[]\n",
    "    comment=0\n",
    "    for token in cursor.get_tokens():\n",
    "        line=token.spelling\n",
    "        if \"//\" in line:\n",
    "            line=line[:line.find(\"//\")]\n",
    "        if \"/*\" in line:\n",
    "            line=line[:line.find(\"/*\")]\n",
    "            comment=1\n",
    "        if  \"*/\" in line:\n",
    "            comment=0\n",
    "        if '\\\"' in line :\n",
    "            continue\n",
    "        if comment==1:\n",
    "            continue\n",
    "        func_body.append(line)\n",
    "    return func_body\n",
    "def has_no_letters(input_string):\n",
    "    return not any(char.isalpha() for char in input_string)\n",
    "def unique_elements_in_order(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "\n",
    "    for elem in seq:\n",
    "        if elem not in seen:\n",
    "            seen.add(elem)\n",
    "            result.append(elem)\n",
    "\n",
    "    return result\n",
    "def not_start_with(str,match_str):\n",
    "    pattern = re.compile(f'^(?!{match_str}).*')\n",
    "    if(pattern.match(str)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def extract_functions(cursor):\n",
    "    functions_data = {}\n",
    "    for node in cursor.get_children():\n",
    "        if node.kind == CursorKind.FUNCTION_DECL or node.kind==CursorKind.CXX_METHOD:\n",
    "            function_name = node.spelling\n",
    "            if(not node.is_definition()):\n",
    "                continue\n",
    "            #排除一些函数\n",
    "            for exclude_str in func_exclude_list:\n",
    "                pattern = re.compile(exclude_str)\n",
    "                if(pattern.match(function_name)):\n",
    "                    function_body = locate_function_body(node)\n",
    "                else:\n",
    "                    function_body=[]\n",
    "            if(len(function_body)==0):\n",
    "                continue\n",
    "            else:\n",
    "                # 使用正则表达式提取变量和函数调用\n",
    "                content = [item for item in function_body if (item and not has_no_letters(item) and not_start_with(item,'__'))]  # 移除空字符串和没有字母的字符串\n",
    "\n",
    "                # 去重并移除C++和C关键字\n",
    "                # unique_tokens = list(set(content))\n",
    "                unique_tokens=unique_elements_in_order(content)\n",
    "                unique_tokens = [token for token in unique_tokens if token not in cpp_and_c_keywords_and_operators]\n",
    "\n",
    "                functions_data[function_name] = unique_tokens\n",
    "\n",
    "    return functions_data\n",
    "\n",
    "def process_cpp_files(folder_path):\n",
    "    cpp_files_data = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.cpp', '.c')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if(file==\"cleaning_motors_control.cpp\"):\n",
    "                    print(file)\n",
    "                translation_unit = run_clang(root,file)\n",
    "                for exclude_str in file_exclude_list:\n",
    "                    #排除一些文件\n",
    "                    pattern = re.compile(exclude_str)\n",
    "                    if(pattern.match(file)):\n",
    "                        functions_data = extract_functions(translation_unit.cursor)\n",
    "                    else:\n",
    "                        functions_data={}\n",
    "                if(len(functions_data)!=0):\n",
    "                    cpp_files_data[file] = functions_data\n",
    "\n",
    "    return cpp_files_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = process_cpp_files(folder_path)\n",
    "    # 将字典转换成JSON字符串\n",
    "    json_string = json.dumps(result, indent=2)\n",
    "\n",
    "    # 将JSON字符串写入文件\n",
    "    file_path = 'output.json'\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json_file.write(json_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉第一层，将剩余的存到一个新字典中\n",
    "import copy\n",
    "result_dict = {}\n",
    "\n",
    "for file_key, functions_dict in result.items():\n",
    "    for func_key, variables_list in functions_dict.items():\n",
    "        result_dict[func_key] = variables_list\n",
    "tree={}\n",
    "for func_key1, value1 in result_dict.items():\n",
    "    tree[func_key1]={\"parents\":[],\"children\":[]}\n",
    "\n",
    "for func_key1, value1 in result_dict.items():\n",
    "    parents=[]\n",
    "    for func_key2, value2 in result_dict.items():\n",
    "        if func_key1==func_key2:\n",
    "            continue\n",
    "        if func_key1 in value2:\n",
    "            parents.append(func_key2)\n",
    "            tree[func_key2][\"children\"].append(func_key1)\n",
    "    if parents:\n",
    "        tree[func_key1][\"parents\"]=parents\n",
    "             \n",
    "\n",
    "# 将字典转换成JSON字符串\n",
    "json_string = json.dumps(tree, indent=2)\n",
    "\n",
    "# 将JSON字符串写入文件\n",
    "file_path = 'tree.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(json_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试能够得到类的成员函数\n",
    "import clang.cindex\n",
    "from clang.cindex import *\n",
    "\n",
    "def method_definitions(cursor):\n",
    "    for i in cursor.get_children():\n",
    "        if i.kind != CursorKind.CXX_METHOD and i.kind!=CursorKind.FUNCTION_DECL:\n",
    "            continue\n",
    "        if not i.is_definition():\n",
    "            continue\n",
    "        yield i\n",
    "\n",
    "def extract_definition(cursor):\n",
    "    filename = cursor.location.file.name\n",
    "    with open(filename, 'r') as fh:\n",
    "        contents = fh.read()\n",
    "    return contents[cursor.extent.start.offset: cursor.extent.end.offset]\n",
    "\n",
    "idx = Index.create()\n",
    "tu = idx.parse('temp2.cpp', ['-x', 'c++','-I/home/tfpeng/codeparser/modules/monitor/include/'])\n",
    "defns = method_definitions(tu.cursor)\n",
    "for defn in defns:\n",
    "    print(extract_definition(defn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def find_header_files(root_folder):\n",
    "    header_files = []\n",
    "    \n",
    "    # 遍历文件夹及其子文件夹\n",
    "    for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "        # 使用glob模块查找.h和.hpp文件\n",
    "        header_files.extend(glob.glob(os.path.join(foldername, '*.h')))\n",
    "        header_files.extend(glob.glob(os.path.join(foldername, '*.hpp')))\n",
    "\n",
    "    return header_files\n",
    "def read_header_files(root_folder):\n",
    "    header_files_content = []\n",
    "\n",
    "    # 遍历文件夹及其子文件夹\n",
    "    for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "        # 使用glob模块查找.h和.hpp文件\n",
    "        header_files = glob.glob(os.path.join(foldername, '*.h')) + glob.glob(os.path.join(foldername, '*.hpp'))\n",
    "        \n",
    "        # 读取每个头文件的内容并添加到列表\n",
    "        for header_file in header_files:\n",
    "            with open(header_file, 'r', encoding='utf-8',errors='ignore') as file:\n",
    "                header_files_content.append(file.read())\n",
    "\n",
    "    # 将所有内容合并成一个字符串\n",
    "    all_content = '\\n'.join(header_files_content)\n",
    "    return all_content\n",
    "# 替换为实际的文件夹路径\n",
    "folder_path = \"/home/tfpeng/codeparser/\"\n",
    "\n",
    "# 获取所有.h和.hpp文件\n",
    "all_header_content = read_header_files(folder_path)\n",
    "\n",
    "print(all_header_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05405dd40f2c617f5a4e17891f55ae2cfdb55ea9402589a2fe2ccf648affaf28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
